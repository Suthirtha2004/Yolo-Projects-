{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "46e8e0fe",
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "!pip install roboflow\n",
    "\n",
    "\n",
    "from roboflow import Roboflow\n",
    "rf = Roboflow(api_key=\"xxxxxxxxxxxxxxxxx\") #Give your api_key\n",
    "project = rf.workspace(\"name_of_workspace\").project(\"license-project-name\")\n",
    "version = project.version(1)\n",
    "dataset = version.download(\"yolov8\")\n",
    "                "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0029b817",
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "from ultralytics import YOLO\n",
    "\n",
    "model = YOLO(\"yolov8n.pt\")\n",
    "results = model.train(data=\"/License-Plate-Detector-1/data.yaml\",epochs=100,save=True) #give your path to data.yaml"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fae3fef6",
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "import cv2\n",
    "\n",
    "from ultralytics import YOLO\n",
    "\n",
    "# Load the YOLO model\n",
    "model = YOLO(\"best.pt\") #path to your model \n",
    "\n",
    "# Open the video file\n",
    "video_path = \"demo.mp4\" #demo video path for testing\n",
    "cap = cv2.VideoCapture(video_path)\n",
    "\n",
    "# Get video properties\n",
    "frame_width = int(cap.get(cv2.CAP_PROP_FRAME_WIDTH))\n",
    "frame_height = int(cap.get(cv2.CAP_PROP_FRAME_HEIGHT))\n",
    "fps = int(cap.get(cv2.CAP_PROP_FPS))\n",
    "\n",
    "\n",
    "output_video_path = \"/content/output_video.mp4\"\n",
    "fourcc = cv2.VideoWriter_fourcc(*'mp4v') \n",
    "out = cv2.VideoWriter(output_video_path, fourcc, fps, (frame_width, frame_height))\n",
    "\n",
    "# Loop through the video frames\n",
    "while cap.isOpened():\n",
    "    # Read a frame from the video\n",
    "    success, frame = cap.read()\n",
    "\n",
    "    if success:\n",
    "        # Run YOLO inference on the frame\n",
    "        results = model(frame)\n",
    "\n",
    "        # Visualize the results on the frame\n",
    "        annotated_frame = results[0].plot()\n",
    "\n",
    "        # Write the annotated frame to the output video file\n",
    "        out.write(annotated_frame)\n",
    "\n",
    "    else:\n",
    "        # Break the loop if the end of the video is reached\n",
    "        break\n",
    "\n",
    "# Release the video capture object and the video writer object\n",
    "cap.release()\n",
    "out.release()\n",
    "\n",
    "print(f\"Annotated video saved to {output_video_path}\")"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
